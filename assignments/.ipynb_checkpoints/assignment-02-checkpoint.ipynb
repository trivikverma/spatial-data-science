{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <img style=\"float: left; padding-right: 10px; width: 200px\" src=\"https://raw.githubusercontent.com/trivikverma/researchgroup/master/assets/media/logo.png\"> EPA-122A *Spatial* Data Science \n",
    "\n",
    "\n",
    "## Assignment 2: Geographic Visualisation\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ``Instructions``\n",
    "\n",
    "This assignment puts together what you learned in **Weeks 3-4**. Assignment 3 will build upon what you do in Assignment 2. \n",
    "\n",
    "_Note:_ Go through **labs and homeworks 03-04** before starting this assignment.\n",
    "\n",
    "#### 1.1 Submission\n",
    "\n",
    "Please submit the results by Brightspace under **Assignment 02**, using a single file as example,\n",
    "\n",
    "```text\n",
    "firstname_secondname_thirdname_lastname_02.html\n",
    "\n",
    "```\n",
    "\n",
    "**If your file is not named in lowercase letters as mentioned above, your assignment will not be read by the script that works to compile 200 assignments and you will miss out on the grades. I don't want that, so be exceptionally careful that you name it properly. Don't worry if you spelled your name incorrectly. I want to avoid a situation where I have 200 assignments all called assignment_02.html**\n",
    "\n",
    "Please **do not** submit any data or files other than the ``html file``.\n",
    "\n",
    "Don't worry about your submission _rendering without the images_ **after** you submitted the file on brightspace. That is a brigthspace related issue of viewing your own submission but when I download all assignments as a batch file, I get all your images and code as you intended to submit. So make sure that your html shows everything you want us to see **before you submit**. \n",
    "\n",
    "#### 1.2 How do you convert to HTML? \n",
    "\n",
    "There are 2 ways, \n",
    "\n",
    "1. from a running notebook, you can convert it into html by clicking on the file tab on the main menu of Jupyter Lab \n",
    "    * File &rightarrow; Export Notebooks as... &rightarrow; Export Notebook to HTML\n",
    "2. go to terminal or command line and type\n",
    "    * ``jupyter nbconvert --to html <notebook_name>.ipynb  ``\n",
    "\n",
    "#### 1.3 Learning Objectives\n",
    "\n",
    "This assignment is designed to support three different learning objectives. After completing the following exercises you will be able to:\n",
    "\n",
    "* Combine different datasets\n",
    "* Explore and Visualise Geographic data\n",
    "* Plot (graphs, scatter plots, choropleth, etc..) and discuss (observations, outliers or relationships) important information about the data using the `principles of graphical excellence` and `guidelines of exploratory data analysis`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "***\n",
    "\n",
    "# ``Critical Data Science``\n",
    "\n",
    "Throughout the assignment, we encourage you to critically reflect on your choices during the Data Science process. To help you set-up your Critical Data Science process, we have provided you with a 'Guide on Critical Data Science'. Section 3.2 contains a step-by-step approach with key considerations for each part of the data science process. The guide can be found [here](https://trivikverma.github.io/spatial-data-science/resources_index.html#a-guide-to-critical-data-science). Below, you will find specific questions which you can use to reflect on your data science choices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "***\n",
    "\n",
    "# ``Problem``\n",
    "\n",
    "`Problem Statement`: \n",
    "- For this assignment you will use the SHRUG (Socioeconomic High-resolution Rural-Urban Geographic) Platform for India to formulate a hypothesis/RQ and conduct an exploratory data analysis. \n",
    "- To formulate the hypothesis, provide at least `two measurements` that may be related to each other (for example: your hypothesis is that areas with `high air pollution` also have relative high `night light pollution`). And explain why? For example, higher night lights pollution entails densification and nighttime activity. This is possible when many people are clustered together for exchnage of goods and services in a city, ultimately leading to more pollution due to use of resources, traffic and mobility, use of water, discharge of pollutants from cars and factories, etc. \n",
    "- Be explicit about how you define these measurements using markdown cells (for example: how do you measure the air pollution, and how do you measure the levels of light pollution during the night?). Do you use variables to proxy any of these effects?\n",
    "- Observe that the measurements have a normative value attached to it (for example: according to your hypothesis, `high levels` of air pollution in an area is of `more` interest). Please do not assume that there is only one normative definition of a certain measurement and skip your reasoning.\n",
    "- On the basis of the hypothesis and its associated measurements, you will conduct some exploratory/spatial data analysis and provide a reflection of how your hypothesis manifests spatially, using maps and other aiding plots. \n",
    "\n",
    "_Note:_ I am not looking for mathematical equations as justification, but you are welcome to also form simple relations and show them in markdown. \n",
    "\n",
    "A formalised example:\n",
    "\n",
    "\n",
    "> I hypothesise that district in India with relatively high air pollution also have high levels of light pollution, due to high levels of [economic activity](https://www.imf.org/en/Publications/fandd/issues/2019/09/satellite-images-at-night-and-economic-growth-yao).\n",
    "\n",
    ">Definitions of metrics:\n",
    ">- I will measure these effects at district level for all variables.\n",
    ">- Surface PM2.5 pollution (estimated annual ground-level fine particulate matter (PM2.5))\n",
    ">- Night time lights (night time luminosity)\n",
    ">- Facebook relative wealth index (measured as an index between 0 and 1). The index is determined by a machine-learning model that collects target variables from traditional survey data spatially linked to features constructed from non-traditional data like high-resolution satellite imagery, data from mobile phone networks, and topographic maps, as well as aggregated and deidentified connectivity data from Facebook. Used in this analysis as a proxy for wealth and economic activity. This is arguably an oversimplification of the concept of inequality but is considered a suitable approximation given the available datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "***\n",
    "\n",
    "# ``Tasks``\n",
    "\n",
    "For your convenience, the assignment has been divided into the following tasks, \n",
    "\n",
    "**Exercise 1**: \n",
    "1. Formulate a hypothesis for this assignment as explained above in `problem statement`. \n",
    "2. Using a critical data science lens, evaluate your hypothesis and contrast it with your previous assignment (A1). The following questions can be used as guides to carry out this task. \n",
    "    - Were there any design choices you would make differently this time? Why? (Because of data availability/ methodology for using certain columns as a proxy?)  \n",
    "    - Explain what your dependent variable is. Explain your choice of independent variables.\n",
    "    - Would you wish to include any variables that are not available? How is the inclusion beneficial for the hypothesis? Are there any variables (proxies) present with which you could replace these missing values?\n",
    "    - Would that have an effect on your outcomes? Think about bias in the data. Explain your reasoning.\n",
    "    - Reflect on any cases in which this hypothesis will be rejected? Why?\n",
    "    - Reflect on cases in which the hypothesis will be falsely rejected or falsely accepted? Think about bias in the data and in your own reasoning.\n",
    "    - Reflect if there are any important perspectives that you are not taking into account by choosing this hypothesis?\n",
    "\n",
    "**Exercise 2**:\n",
    "1. Use two datasets: merge a shapefile and a csv file.\n",
    "2. Clean your data and make it tabular for your own good! (think about weeks 1-2 and assignment 1)\n",
    "4. Carry out an exploratory data analysis (EDA)\n",
    "5. Report on your hypothesis results both in relationships of the variables and spatial manifestation of the outcome. \n",
    "    * Use at least **3 figures** to support your analysis. Think about exploratory data analysis (build data, clean data, explore global/group properties). \n",
    "    * These figures should have followed the principles of graphical excellence. Using markdown, write explicity under **each** figure at least **3 principles of excellence** you have used to make it.\n",
    "    * Create **choropleths** to display **region-specific information** (ex. population, voting choice or jobs availability) together with **some other elements like the sea, canals, centroids, or amenities** (you may try Open Street Maps data - using `osmnx`).\n",
    "    * Be careful with the use of color (and try to be inclusive of color blind people)\n",
    "    * Use **one method** from the lectures to discuss what you observe for your variable(s). Examples below,\n",
    "          * local or global spatial autocorrelation\n",
    "          * network measures\n",
    "          * spatial weights / spatial lag\n",
    "          * binning\n",
    "          * feature scaling, normalisation or standardisation\n",
    "\n",
    "\n",
    "**Exercise 3**: \n",
    "1. Critically reflect on your EDA and visualizations following the questions below. \n",
    "    - Do they show the relevant information in a precise manner or is the data skewed or biased due to certain choices that you have made in the EDA? \n",
    "    - Could they be further reduced/enhanced? (Refer/Use [Critical Data Science Handbook](https://trivikverma.github.io/spatial-data-science/resources_index.html#a-guide-to-critical-data-science) where needed)\n",
    "\n",
    "***Remember to always document your code! Justify everything you do (cleaning data, analysisng data, exploring data, defining hypothesis or measurements, etc.) using markdown cells as you go through the notebook.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "***\n",
    "\n",
    "# ``Data``\n",
    "\n",
    "Information about the SHRUG can be found [here](https://docs.devdatalab.org/). On this [website](https://www.devdatalab.org/shrug_download/) you can download data for your variables of interest (in csv format) and the shapefiles that you can use for mapping the variables. Put the data in a convenient location on your computer or laptop, ideally in a folder called **data** which is next to this **jupyter notebook**. Make sure youâ€™ve set your working directory in the [correct manner](https://www.delftstack.com/howto/python/relative-path-in-python/).\n",
    "\n",
    "These are a big files and it may take a while to load onto your laptop and into Python (running on the jupyter labs environment). \n",
    "\n",
    "As mentioned above in the problem introduction, you will use at least two datasets.\n",
    "\n",
    "1. **First Dataset:** Download Shapefiles of SHRUG for the geographic level of your assignment (shrid, district, subdistrict)\n",
    "2. **Second Dataset:** Get a second dataset of your choice in SHRUG using the links above (curate this dataset as you like)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "***\n",
    "\n",
    "# ``Start your analysis``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "# use many cells if you like to structure your code well\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
